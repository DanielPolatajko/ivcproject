{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path(os.getcwd())\n",
    "par = cwd.parent\n",
    "pytorch = cwd/\"pytorch_mlp_framework\"\n",
    "mlp  = cwd / \"mlp\"\n",
    "sys.path.append(pytorch) # go to parent dir\n",
    "sys.path.append(mlp) # go to parent dir\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/pytorch_mlp_framework\n"
     ]
    }
   ],
   "source": [
    "print(pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import mlp.data_providers as data_providers\n",
    "from pytorch_mlp_framework.arg_extractor import get_args\n",
    "from pytorch_mlp_framework.experiment_builder import ExperimentBuilder\n",
    "from pytorch_mlp_framework.model_architectures import TrialNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "data_path= cwd / \"data\" / \"JPEGImages\" / \"480p\" / \"bear\"\n",
    "mask_path = cwd / \"data\" / \"Annotations\" / \"480p\" / \"bear\"\n",
    "#data_path= r\"C:\\Data_Science\\Image and Vision Computing\\Assignment\\Data\\JPEGImages\\480p\\bear\"\n",
    "#mask_path= r\"C:\\Data_Science\\Image and Vision Computing\\Assignment\\Data\\Annotations\\480p\\bear\"\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import decimate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "os.chdir(data_path)\n",
    "images = [str(data_path)+\"/\"+g for g in glob.glob(\"*.jpg\")]\n",
    "os.chdir(mask_path)\n",
    "masks= [str(mask_path)+\"/\"+g for g in glob.glob(\"*.png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(img,n):\n",
    "    img_d=decimate(img, n, n=2, ftype='fir',axis=0, zero_phase=True)\n",
    "    return img_d.astype(\"uint8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=4\n",
    "#a = np.array([np.asarray(Image.open(msk)).shape for msk in masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=np.asarray([down_sample(np.asarray(Image.open(img)),N) for img in images])\n",
    "all_masks=np.asarray([down_sample(np.asarray(Image.open(msk)),N) for msk in masks])\n",
    "N_Train=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 120, 854, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=all_images[:N_Train].swapaxes(1,3).swapaxes(2,3)\n",
    "y_train=all_masks[:N_Train] \n",
    "X_val=all_images[N_Train:].swapaxes(1,3).swapaxes(2,3) \n",
    "y_val=all_masks[N_Train:]\n",
    "X_test=all_images[N_Train:].swapaxes(1,3).swapaxes(2,3) \n",
    "y_test=all_masks[N_Train:] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_data = data_providers.DataProvider(X_train,y_train,batch_size)\n",
    "val_data = data_providers.DataProvider(X_val,y_val,batch_size)\n",
    "test_data = data_providers.DataProvider(X_test,y_test,batch_size)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_data_loader=DataLoader(train_data,batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_data_loader=DataLoader(val_data,batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_data_loader=DataLoader(test_data,batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 120, 854])\n",
      "Block is built, output volume is torch.Size([10, 2, 120, 854])\n"
     ]
    }
   ],
   "source": [
    "tn=TrialNetwork(input_shape=X_train[:batch_size].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name= \"first\"\n",
    "num_epochs = 3\n",
    "weight_decay_coefficient =0\n",
    "use_gpu=False\n",
    "continue_from_epoch=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "#import importlib\n",
    "#importlib.reload(pytorch_mlp_framework.model_architectures)\n",
    "from pytorch_mlp_framework.model_architectures import TrialNetwork\n",
    "from pytorch_mlp_framework.experiment_builder import ExperimentBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CPU\n",
      "cpu\n",
      "here\n",
      "System learnable parameters\n",
      "model.layer_dict.conv_0.weight torch.Size([16, 3, 8, 8])\n",
      "model.layer_dict.conv_0.bias torch.Size([16])\n",
      "model.layer_dict.conv_1.weight torch.Size([8, 16, 8, 8])\n",
      "model.layer_dict.conv_1.bias torch.Size([8])\n",
      "model.layer_dict.conv_T_2.weight torch.Size([8, 16, 8, 8])\n",
      "model.layer_dict.conv_T_2.bias torch.Size([16])\n",
      "model.layer_dict.conv_T_3.weight torch.Size([16, 2, 8, 8])\n",
      "model.layer_dict.conv_T_3.bias torch.Size([2])\n",
      "Total number of parameters 21546\n",
      "Total number of conv layers 4\n",
      "Total number of linear layers 0\n",
      "tensor(-0.0527)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0527, accuracy: 0.4322:  20%|██        | 1/5 [00:08<00:35,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0519)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0519, accuracy: 0.4336:  40%|████      | 2/5 [00:18<00:27,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0579)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0579, accuracy: 0.4341:  60%|██████    | 3/5 [00:26<00:17,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0508)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0508, accuracy: 0.4320:  80%|████████  | 4/5 [00:35<00:08,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0538, accuracy: 0.4280: 100%|██████████| 5/5 [00:44<00:00,  8.88s/it]\n",
      "loss: -0.0536, accuracy: 0.4310: 100%|██████████| 3/3 [00:29<00:00,  9.91s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 0: train_acc_0.4320_train_loss_-0.0534_val_acc_0.4309_val_loss_-0.0525 epoch time 74.1443 seconds\n",
      "tensor(-0.0555)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0555, accuracy: 0.4335:  20%|██        | 1/5 [00:09<00:36,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0564)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0564, accuracy: 0.4367:  40%|████      | 2/5 [00:17<00:26,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0496)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0496, accuracy: 0.4275:  60%|██████    | 3/5 [00:26<00:17,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0512, accuracy: 0.4309:  80%|████████  | 4/5 [00:35<00:08,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0544, accuracy: 0.4314: 100%|██████████| 5/5 [00:43<00:00,  8.72s/it]\n",
      "loss: -0.0548, accuracy: 0.4316: 100%|██████████| 3/3 [00:25<00:00,  8.63s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1: train_acc_0.4320_train_loss_-0.0534_val_acc_0.4309_val_loss_-0.0525 epoch time 69.4812 seconds\n",
      "tensor(-0.0538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0538, accuracy: 0.4332:  20%|██        | 1/5 [00:09<00:38,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0591, accuracy: 0.4304:  40%|████      | 2/5 [00:18<00:28,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0517, accuracy: 0.4331:  60%|██████    | 3/5 [00:27<00:18,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0505)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0505, accuracy: 0.4329:  80%|████████  | 4/5 [00:36<00:09,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0521)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0521, accuracy: 0.4303: 100%|██████████| 5/5 [00:45<00:00,  9.04s/it]\n",
      "loss: -0.0491, accuracy: 0.4325: 100%|██████████| 3/3 [00:25<00:00,  8.43s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 2: train_acc_0.4320_train_loss_-0.0534_val_acc_0.4309_val_loss_-0.0525 epoch time 70.5249 seconds\n",
      "Generating test set evaluation metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0491, accuracy: 0.4325: 100%|██████████| 3/3 [00:25<00:00,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conv_experiment = ExperimentBuilder(network_model=tn,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    num_epochs=num_epochs,\n",
    "                                    weight_decay_coefficient=weight_decay_coefficient,\n",
    "                                    use_gpu=use_gpu,\n",
    "                                    continue_from_epoch=continue_from_epoch,\n",
    "                                    train_data=train_data, val_data=val_data,\n",
    "                                    test_data=test_data)  # build an experiment object\n",
    "experiment_metrics, test_metrics = conv_experiment.run_experiment()  # run experiment and return experiment metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = get_args()  # get arguments from command line\n",
    "class Bogus:\n",
    "    def __init__(self):\n",
    "        self.x=3\n",
    "    \n",
    "\n",
    "args=Bogus()\n",
    "args.seed = 7112018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=args.seed)  # set the seeds for the experiment\n",
    "torch.manual_seed(seed=args.seed)  # sets pytorch's seed\n",
    "\n",
    "# set up data augmentation transforms for training and testing\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_data = data_providers.CIFAR100(root='data', set_name='train',\n",
    "                 transform=transform_train,\n",
    "                 download=True)  # initialize our rngs using the argument set seed\n",
    "val_data = data_providers.CIFAR100(root='data', set_name='val',\n",
    "                 transform=transform_test,\n",
    "                 download=True)  # initialize our rngs using the argument set seed\n",
    "test_data = data_providers.CIFAR100(root='data', set_name='test',\n",
    "                 transform=transform_test,\n",
    "                 download=True)  # initialize our rngs using the argument set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(val_data.data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
