{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path(os.getcwd())\n",
    "par = cwd.parent\n",
    "pytorch = cwd/\"pytorch_mlp_framework\"\n",
    "mlp  = cwd / \"mlp\"\n",
    "sys.path.append(pytorch) # go to parent dir\n",
    "sys.path.append(mlp) # go to parent dir\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/pytorch_mlp_framework\n"
     ]
    }
   ],
   "source": [
    "print(pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import mlp.data_providers as data_providers\n",
    "from pytorch_mlp_framework.arg_extractor import get_args\n",
    "from pytorch_mlp_framework.experiment_builder import ExperimentBuilder\n",
    "from pytorch_mlp_framework.model_architectures import TrialNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "data_path= cwd / \"data\" / \"JPEGImages\" / \"480p\" / \"bear\"\n",
    "mask_path = cwd / \"data\" / \"Annotations\" / \"480p\" / \"bear\"\n",
    "#data_path= r\"C:\\Data_Science\\Image and Vision Computing\\Assignment\\Data\\JPEGImages\\480p\\bear\"\n",
    "#mask_path= r\"C:\\Data_Science\\Image and Vision Computing\\Assignment\\Data\\Annotations\\480p\\bear\"\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import decimate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "os.chdir(data_path)\n",
    "images = [str(data_path)+\"/\"+g for g in glob.glob(\"*.jpg\")]\n",
    "os.chdir(mask_path)\n",
    "masks= [str(mask_path)+\"/\"+g for g in glob.glob(\"*.png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(img,n):\n",
    "    img_d=decimate(img, n, n=2, ftype='fir',axis=0, zero_phase=True)\n",
    "    return img_d.astype(\"uint8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00044.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00034.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00073.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00031.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00069.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00012.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00061.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00000.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00054.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00067.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00003.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00071.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00024.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00016.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00009.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00026.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00081.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00076.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00032.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00062.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00041.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00060.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00015.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00021.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00011.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00013.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00001.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00040.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00020.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00002.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00064.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00039.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00043.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00047.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00079.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00045.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00005.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00058.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00033.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00022.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00063.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00056.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00027.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00004.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00074.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00052.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00075.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00072.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00048.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00049.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00006.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00055.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00007.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00025.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00046.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00010.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00068.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00059.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00053.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00050.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00008.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00051.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00065.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00019.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00030.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00042.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00029.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00028.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00037.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00080.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00036.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00017.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00023.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00057.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00066.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00038.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00070.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00035.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00018.png\n",
      "[480 854]\n",
      "/afs/inf.ed.ac.uk/user/s15/s1505448/Documents/ivc/ivcproject/data/Annotations/480p/bear/00014.png\n"
     ]
    }
   ],
   "source": [
    "N=4\n",
    "a = np.array([np.asarray(Image.open(msk)).shape for msk in masks])\n",
    "count = 0\n",
    "for i in range(len(a)):\n",
    "    print(a[i])\n",
    "    print(masks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=np.asarray([down_sample(np.asarray(Image.open(img)),N) for img in images])\n",
    "all_masks=np.asarray([down_sample(np.asarray(Image.open(msk)),N) for msk in masks])\n",
    "N_Train=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 120, 854, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=all_images[:N_Train].swapaxes(1,3).swapaxes(2,3)\n",
    "y_train=all_masks[:N_Train] \n",
    "X_val=all_images[N_Train:].swapaxes(1,3).swapaxes(2,3) \n",
    "y_val=all_masks[N_Train:]\n",
    "X_test=all_images[N_Train:].swapaxes(1,3).swapaxes(2,3) \n",
    "y_test=all_masks[N_Train:] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_data = data_providers.DataProvider(X_train,y_train,batch_size)\n",
    "val_data = data_providers.DataProvider(X_val,y_val,batch_size)\n",
    "test_data = data_providers.DataProvider(X_test,y_test,batch_size)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_data_loader=DataLoader(train_data,batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_data_loader=DataLoader(val_data,batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_data_loader=DataLoader(test_data,batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 120, 854])\n",
      "Block is built, output volume is torch.Size([10, 2, 120, 854])\n"
     ]
    }
   ],
   "source": [
    "tn=TrialNetwork(input_shape=X_train[:batch_size].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name= \"first\"\n",
    "num_epochs = 3\n",
    "weight_decay_coefficient =0\n",
    "use_gpu=False\n",
    "continue_from_epoch=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "#import importlib\n",
    "#importlib.reload(pytorch_mlp_framework.model_architectures)\n",
    "from pytorch_mlp_framework.model_architectures import TrialNetwork\n",
    "from pytorch_mlp_framework.experiment_builder import ExperimentBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CPU\n",
      "cpu\n",
      "here\n",
      "System learnable parameters\n",
      "model.layer_dict.conv_0.weight torch.Size([16, 3, 8, 8])\n",
      "model.layer_dict.conv_0.bias torch.Size([16])\n",
      "model.layer_dict.conv_1.weight torch.Size([8, 16, 8, 8])\n",
      "model.layer_dict.conv_1.bias torch.Size([8])\n",
      "model.layer_dict.conv_T_2.weight torch.Size([8, 16, 8, 8])\n",
      "model.layer_dict.conv_T_2.bias torch.Size([16])\n",
      "model.layer_dict.conv_T_3.weight torch.Size([16, 2, 8, 8])\n",
      "model.layer_dict.conv_T_3.bias torch.Size([2])\n",
      "Total number of parameters 21546\n",
      "Total number of conv layers 4\n",
      "Total number of linear layers 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 741.6476, accuracy: 0.8074: 100%|██████████| 5/5 [00:31<00:00,  6.28s/it]\n",
      "loss: 755.7893, accuracy: 0.8048: 100%|██████████| 3/3 [00:18<00:00,  6.25s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 0: train_acc_0.8070_train_loss_740.8199_val_acc_0.8067_val_loss_745.6182 epoch time 50.1562 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 727.3151, accuracy: 0.8076: 100%|██████████| 5/5 [00:30<00:00,  6.20s/it]\n",
      "loss: 757.3566, accuracy: 0.8046: 100%|██████████| 3/3 [00:18<00:00,  6.19s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1: train_acc_0.8070_train_loss_740.8068_val_acc_0.8068_val_loss_741.1724 epoch time 49.5431 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 733.4843, accuracy: 0.8069:  60%|██████    | 3/5 [00:20<00:13,  6.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-fcc8170d399e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     test_data=test_data)  # build an experiment object\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mexperiment_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run experiment and return experiment metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ivc/ivcproject/pytorch_mlp_framework/experiment_builder.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0;31m#print(temp[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# take a training iter step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                     \u001b[0mcurrent_epoch_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add current iter loss to the train loss list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0mcurrent_epoch_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add current iter acc to the train acc list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ivc/ivcproject/pytorch_mlp_framework/experiment_builder.py\u001b[0m in \u001b[0;36mrun_train_iter\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m         x, y = x.float().to(device=self.device), y.float().to(\n\u001b[1;32m    133\u001b[0m             device=self.device)  # send data to device as torch tensors\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# forward the data in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ivc/ivcproject/pytorch_mlp_framework/model_architectures.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv_T_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv_T_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ivc/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    776\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    777\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_experiment = ExperimentBuilder(network_model=tn,\n",
    "                                    experiment_name=experiment_name,\n",
    "                                    num_epochs=num_epochs,\n",
    "                                    weight_decay_coefficient=weight_decay_coefficient,\n",
    "                                    use_gpu=use_gpu,\n",
    "                                    continue_from_epoch=continue_from_epoch,\n",
    "                                    train_data=train_data, val_data=val_data,\n",
    "                                    test_data=test_data)  # build an experiment object\n",
    "experiment_metrics, test_metrics = conv_experiment.run_experiment()  # run experiment and return experiment metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = get_args()  # get arguments from command line\n",
    "class Bogus:\n",
    "    def __init__(self):\n",
    "        self.x=3\n",
    "    \n",
    "\n",
    "args=Bogus()\n",
    "args.seed = 7112018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=args.seed)  # set the seeds for the experiment\n",
    "torch.manual_seed(seed=args.seed)  # sets pytorch's seed\n",
    "\n",
    "# set up data augmentation transforms for training and testing\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_data = data_providers.CIFAR100(root='data', set_name='train',\n",
    "                 transform=transform_train,\n",
    "                 download=True)  # initialize our rngs using the argument set seed\n",
    "val_data = data_providers.CIFAR100(root='data', set_name='val',\n",
    "                 transform=transform_test,\n",
    "                 download=True)  # initialize our rngs using the argument set seed\n",
    "test_data = data_providers.CIFAR100(root='data', set_name='test',\n",
    "                 transform=transform_test,\n",
    "                 download=True)  # initialize our rngs using the argument set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(val_data.data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
